"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7558],{5363:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>i,default:()=>d,frontMatter:()=>l,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"infra-monitoring/kubernetes","title":"Kubernetes","description":"The recommended setup for infra monitoring with CubeAPM is to use OpenTelemetry (OTel) Collector for collecting the metrics from various infrastructure components and sending them to CubeAPM. CubeAPM then provides visualization and alerting on the collected metrics.","source":"@site/docs/infra-monitoring/3_kubernetes.md","sourceDirName":"infra-monitoring","slug":"/infra-monitoring/kubernetes","permalink":"/infra-monitoring/kubernetes","draft":false,"unlisted":false,"editUrl":"https://github.com/cubeapm/docs/docs/docs/infra-monitoring/3_kubernetes.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"slug":"/infra-monitoring/kubernetes"},"sidebar":"tutorialSidebar","previous":{"title":"Bare Metal / Virtual Machine","permalink":"/infra-monitoring/bare-metal-virtual-machine"},"next":{"title":"AWS CloudWatch","permalink":"/infra-monitoring/aws-cloudwatch"}}');var s=t(4848),o=t(8453);const l={sidebar_position:3,slug:"/infra-monitoring/kubernetes"},i="Kubernetes",a={},c=[{value:"Installation",id:"installation",level:2},{value:"Monitoring processes",id:"monitoring-processes",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"kubernetes",children:"Kubernetes"})}),"\n",(0,s.jsx)(n.p,{children:"The recommended setup for infra monitoring with CubeAPM is to use OpenTelemetry (OTel) Collector for collecting the metrics from various infrastructure components and sending them to CubeAPM. CubeAPM then provides visualization and alerting on the collected metrics."}),"\n",(0,s.jsxs)(n.p,{children:["The official OTel Collector helm chart is available at ",(0,s.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-collector",children:"https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-collector"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["On k8s, the Collector can be in two modes - ",(0,s.jsx)(n.strong,{children:"daemonset"})," (collector runs as a daemonset on each k8s node) and ",(0,s.jsx)(n.strong,{children:"deployment"})," (collector runs as a k8s deployment with specified number of pods). For complete k8s monitoring, the Collector needs to be run both as daemonset and deployment."]}),"\n",(0,s.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Add the OpenTelemetry Helm chart repository."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts\n# Use the following command to update if the repo is already added.\nhelm repo update open-telemetry\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Copy the files below and save as ",(0,s.jsx)(n.code,{children:"otel-collector-daemonset.yaml"})," and ",(0,s.jsx)(n.code,{children:"otel-collector-deployment.yaml"})," respectively. Edit them to customize the configuration as per your requirements."]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"otel-collector-daemonset.yaml"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'mode: daemonset\nimage:\n  repository: "otel/opentelemetry-collector-contrib"\n  # tag: 0.112.0\npresets:\n  kubernetesAttributes:\n    enabled: true\n  hostMetrics:\n    enabled: true\n  kubeletMetrics:\n    enabled: true\n  logsCollection:\n    enabled: true\n    # includeCollectorLogs: true\n    storeCheckpoints: true\nconfig:\n  exporters:\n    debug:\n      verbosity: detailed\n      sampling_initial: 5\n      sampling_thereafter: 1\n    otlphttp/metrics:\n      metrics_endpoint: http://<cubeapm_endpoint>:3130/api/metrics/v1/save/otlp\n      retry_on_failure:\n        enabled: false\n    otlphttp/logs:\n      logs_endpoint: http://<cubeapm_endpoint>:3130/api/logs/insert/opentelemetry/v1/logs\n      headers:\n        Cube-Stream-Fields: k8s.namespace.name,k8s.deployment.name,k8s.statefulset.name\n    otlp/traces:\n      endpoint: <cubeapm_endpoint>:4317\n      tls:\n        insecure: true\n  processors:\n    batch: {}\n    resourcedetection:\n      detectors: ["system"]\n      system:\n        hostname_sources: ["os"]\n    resource/host.name:\n      attributes:\n        - key: host.name\n          value: "${env:K8S_NODE_NAME}"\n          action: upsert\n    resource/cube.environment:\n      attributes:\n        - key: cube.environment\n          value: UNSET\n          action: upsert\n    # filter/metrics:\n    #   error_mode: ignore\n    #   metrics:\n    #     metric:\n    #       # only include my-namespace\n    #       - resource.attributes["k8s.namespace.name"] != "my-namespace"\n    # filter/logs:\n    #   error_mode: ignore\n    #   logs:\n    #     log_record:\n    #       # only include my-namespace\n    #       - resource.attributes["k8s.namespace.name"] != "my-namespace"\n    # transform/logs_redact:\n    #   error_mode: ignore\n    #   log_statements:\n    #     - context: log\n    #       statements:\n    #         # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/ottlfuncs#replace_pattern\n    #         # - replace_pattern(attributes["http.url"], "client_id=[^&]+", "client_id=[REDACTED]")\n    #         - replace_pattern(body, "\\"(token|password)\\":\\"[^\\"]*\\"", "\\"$$1\\":\\"****\\"")\n    # transform/logs_extract_fields:\n    #   error_mode: ignore\n    #   log_statements:\n    #     - context: log\n    #       statements:\n    #         # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/ottlfuncs#extractpatterns\n    #         - set(cache, ExtractPatterns(body, "\\\\[(?P<log_level>debug|info|warn|warning|error)\\\\]"))\n    #         - flatten(cache, "")\n    #         - merge_maps(attributes, cache, "upsert")\n    transform/logs_parse_json_body:\n      error_mode: ignore\n      log_statements:\n        - context: log\n          conditions:\n            - body != nil and IsString(body) and Substring(body, 0, 2) == "{\\""\n          statements:\n            - set(cache, ParseJSON(body))\n            - flatten(cache, "")\n            - merge_maps(attributes, cache, "upsert")\n            # - set(time, Time(attributes["Timestamp"], "%Y-%m-%dT%H:%M:%S%j"))\n            # - set(severity_text, "DEBUG") where attributes["Level"] == "Debug"\n            # - set(severity_number, 5) where attributes["Level"] == "Debug"\n  receivers:\n    otlp:\n      protocols:\n        grpc: {}\n        http: {}\n    kubeletstats:\n      collection_interval: 60s\n      insecure_skip_verify: true\n      metric_groups:\n        - container\n        - node\n        - pod\n        - volume\n      extra_metadata_labels:\n        # - container.id\n        - k8s.volume.type\n    hostmetrics:\n      collection_interval: 60s\n      scrapers:\n        cpu:\n        disk:\n        # load:\n        filesystem:\n        memory:\n        network:\n        # paging:\n        # processes:\n        # process:\n        #   mute_process_all_errors: true\n  service:\n    pipelines:\n      traces:\n        exporters:\n          # - debug\n          - otlp/traces\n        processors:\n          - memory_limiter\n          - batch\n          # traces would normally have host.name attribute set to pod name.\n          # resourcedetection and resource/host.name processors will override\n          # it with the node name.\n          # - resourcedetection\n          # - resource/host.name\n          - resource/cube.environment\n        receivers:\n          - otlp\n      metrics:\n        exporters:\n          # - debug\n          - otlphttp/metrics\n        processors:\n          - memory_limiter\n          # - filter/metrics\n          - batch\n          - resourcedetection\n          - resource/host.name\n          - resource/cube.environment\n        receivers:\n          - hostmetrics\n          - kubeletstats\n      logs:\n        exporters:\n          # - debug\n          - otlphttp/logs\n        processors:\n          - memory_limiter\n          # - filter/logs\n          # - transform/logs_redact\n          # - transform/logs_extract_fields\n          - transform/logs_parse_json_body\n          - batch\n          - resourcedetection\n          - resource/host.name\n          - resource/cube.environment\n\nclusterRole:\n  rules:\n    # needed for receivers.kubeletstats.extra_metadata_labels.(*)\n    # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/v0.89.0/receiver/kubeletstatsreceiver#role-based-access-control\n    - apiGroups: [""]\n      resources: ["nodes/proxy"]\n      verbs: ["get"]\n\ntolerations:\n  # If some nodes (like control plane nodes) are tainted, pods won\u2019t get\n  # scheduled unless they have matching tolerations. This toleration\n  # allows the pod to be scheduled on any tainted node.\n  - operator: Exists\n'})})]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"otel-collector-deployment.yaml"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'mode: deployment\nimage:\n  repository: "otel/opentelemetry-collector-contrib"\n  # tag: 0.112.0\npresets:\n  kubernetesEvents:\n    enabled: true\n  clusterMetrics:\n    enabled: true\nconfig:\n  exporters:\n    debug:\n      verbosity: detailed\n      sampling_initial: 5\n      sampling_thereafter: 1\n    otlphttp/metrics:\n      metrics_endpoint: http://<cubeapm_endpoint>:3130/api/metrics/v1/save/otlp\n      retry_on_failure:\n        enabled: false\n    otlphttp/k8s-events:\n      logs_endpoint: http://<cubeapm_endpoint>:3130/api/logs/insert/opentelemetry/v1/logs\n      headers:\n        Cube-Stream-Fields: event.domain\n  processors:\n    batch: {}\n    resource/cube.environment:\n      attributes:\n        - key: cube.environment\n          value: UNSET\n          action: upsert\n    transform/logs_flatten_map:\n      error_mode: ignore\n      log_statements:\n        - context: log\n          conditions:\n            - body != nil and IsMap(body)\n          statements:\n            - set(cache, body)\n            - flatten(cache, "")\n            - merge_maps(attributes, cache, "upsert")\n  receivers:\n    k8s_cluster:\n      collection_interval: 60s\n      allocatable_types_to_report:\n        - cpu\n        - memory\n      metrics:\n        k8s.node.condition:\n          enabled: true\n  service:\n    pipelines:\n      metrics:\n        exporters:\n          # - debug\n          - otlphttp/metrics\n        processors:\n          - memory_limiter\n          - batch\n          - resource/cube.environment\n        receivers:\n          - k8s_cluster\n      logs:\n        exporters:\n          # - debug\n          - otlphttp/k8s-events\n        processors:\n          - memory_limiter\n          - transform/logs_flatten_map\n          - batch\n          - resource/cube.environment\n        receivers:\n          - k8sobjects\n'})})]}),"\n",(0,s.jsxs)(n.p,{children:["A sample project with examples of additional Collector configuration, e.g., to monitor Redis, MySQL, etc. is available at ",(0,s.jsx)(n.a,{href:"https://github.com/cubeapm/sample_infra_monitoring",children:"https://github.com/cubeapm/sample_infra_monitoring"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Install the collector using the following commands:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"helm install otel-collector-daemonset open-telemetry/opentelemetry-collector -f otel-collector-daemonset.yaml\nhelm install otel-collector-deployment open-telemetry/opentelemetry-collector -f otel-collector-deployment.yaml\n\n# Use the following commands to update if already installed.\nhelm upgrade otel-collector-daemonset open-telemetry/opentelemetry-collector -f otel-collector-daemonset.yaml\nhelm upgrade otel-collector-deployment open-telemetry/opentelemetry-collector -f otel-collector-deployment.yaml\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"monitoring-processes",children:"Monitoring processes"}),"\n",(0,s.jsx)(n.p,{children:"The configuration above will monitor the k8s cluster at container-level granularity, which is quite sufficient in most of the cases. However, if you are running multiple processes in your containers and need to monitor individual processes as well, it can be enabled as follows:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Enable process level monitoring in ",(0,s.jsx)(n.code,{children:"hostmetrics"})," receiver in the OTel Collector Daemonset."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="otel-collector-daemonset.yaml (hostmetrics)"',children:"config:\n  receivers:\n    hostmetrics:\n      scrapers:\n        // highlight-start\n        # Enable process level monitoring\n        process:\n          resource_attributes:\n            # Enable cgroup info for each process so that we can\n            # link processes to respective containers\n            process.cgroup:\n              enabled: true\n          // highlight-end\n          mute_process_all_errors: true\n"})}),"\n",(0,s.jsx)(n.p,{children:"Enabling process level monitoring generates a lot of metrics. We can reduce the number of metrics by disabling some metrics as follows:"}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"otel-collector-daemonset.yaml (hostmetrics)"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"config:\n  receivers:\n    // highlight-start\n    hostmetrics:\n      collection_interval: 60s\n      scrapers:\n        cpu:\n        disk:\n          exclude:\n            devices:\n              - ^loop.*$\n            match_type: regexp\n          metrics:\n            system.disk.io:\n              enabled: false\n            system.disk.merged:\n              enabled: false\n            system.disk.operation_time:\n              enabled: false\n            system.disk.operations:\n              enabled: false\n            system.disk.pending_operations:\n              enabled: false\n            system.disk.weighted_io_time:\n              enabled: false\n        # load:\n        filesystem:\n          exclude_devices:\n            devices:\n              - ^/dev/loop.*$\n            match_type: regexp\n          metrics:\n            system.filesystem.inodes.usage:\n              enabled: false\n        memory:\n        network:\n          metrics:\n            system.network.connections:\n              enabled: false\n            system.network.dropped:\n              enabled: false\n            system.network.errors:\n              enabled: false\n            system.network.packets:\n              enabled: false\n        # paging:\n        # processes:\n        # Enable process level monitoring\n        process:\n          resource_attributes:\n            # Enable cgroup info for each process so that we can\n            # link processes to respective containers\n            process.cgroup:\n              enabled: true\n          metrics:\n            process.disk.io:\n              enabled: false\n            process.memory.virtual:\n              enabled: false\n            process.uptime:\n              enabled: true\n          mute_process_all_errors: true\n    // highlight-end\n"})})]}),"\n",(0,s.jsxs)(n.p,{children:["CubeAPM will now show process level stats in ",(0,s.jsx)(n.code,{children:"Infrastructure > Host"})," page."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Enable ",(0,s.jsx)(n.code,{children:"container.id"})," attribute in ",(0,s.jsx)(n.code,{children:"kubeletstats"})," receiver to attach container id to each container. This will enable linking of processes to the respective containers."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="otel-collector-daemonset.yaml (kubeletstats)"',children:"config:\n  receivers:\n    kubeletstats:\n    // highlight-start\n    extra_metadata_labels:\n      - container.id\n    // highlight-end\n"})}),"\n",(0,s.jsxs)(n.p,{children:["CubeAPM will now show process level stats in ",(0,s.jsx)(n.code,{children:"Infrastructure > K8s Pod"})," page as well."]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>i});var r=t(6540);const s={},o=r.createContext(s);function l(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);